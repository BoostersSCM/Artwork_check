import streamlit as st
import pdfplumber
import pytesseract
from PIL import Image
from io import BytesIO
import fitz  # PyMuPDF
import re
from spellchecker import SpellChecker

st.set_page_config(page_title="AI/PDF ì˜¤íƒ€ ê²€ì¦ê¸°", layout="wide")

st.title("ğŸ“„ AI/PDF ë‹¨ìƒì ì˜¤íƒ€ ê²€ì¦ê¸° (í•œê¸€+ì˜ë¬¸ í˜¼í•©, Cloud í˜¸í™˜)")
st.markdown("""
ì´ ë„êµ¬ëŠ” **AI ë˜ëŠ” PDF ì›í™” íŒŒì¼**ì˜ í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ê³   
**í•œê¸€ê³¼ ì˜ì–´ì˜ ì² ì ì˜¤ë¥˜ë¥¼ ë™ì‹œì— íƒì§€**í•©ë‹ˆë‹¤.  
Popplerê°€ ì—†ì–´ë„ Streamlit Cloudì—ì„œ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.
---
""")

# OCR ì–¸ì–´ ì„ íƒ
lang_option = st.sidebar.selectbox(
    "OCR ì¸ì‹ ì–¸ì–´",
    ["í•œê¸€ë§Œ (kor)", "ì˜ì–´ë§Œ (eng)", "í•œê¸€+ì˜ì–´ (kor+eng)"],
    index=2
)
lang_code = lang_option.split("(")[-1].replace(")", "").strip()

uploaded_file = st.file_uploader("ğŸ“„ AI ë˜ëŠ” PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "ai"])

# í•œê¸€ ê°„ë‹¨ ì˜¤íƒ€ íŒ¨í„´ (ê¸°ì´ˆ ê·œì¹™ ê¸°ë°˜)
korean_common_typos = {
    "ìœ„í•˜ì‚¬": "ìœ„í•˜ì—¬",
    "ì„­ì¹˜": "ì„­ì·¨",
    "ë°ì¤„": "ë° ì¤„",
    "í•©ë‹ˆë‹¤ë‹ˆë‹¤": "í•©ë‹ˆë‹¤",
    "ì‡ìŠµë‹ˆë‹¤": "ìˆìŠµë‹ˆë‹¤",
    "ã…‚ë‹ˆë‹¤": "ìŠµë‹ˆë‹¤"
}

if uploaded_file:
    with st.spinner("ğŸ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            pdf_path = tmp_file.name

        extracted_text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                text_blocks = [p.extract_text() for p in pdf.pages if p.extract_text()]
                extracted_text = "\n".join(text_blocks)
        except Exception:
            extracted_text = ""

        if len(extracted_text.strip()) < 50:
            st.info(f"ğŸ“¸ í…ìŠ¤íŠ¸ ì¸ì‹ ë¶ˆê°€ â†’ OCR ëª¨ë“œ ì „í™˜ ({lang_option})")
            doc = fitz.open(pdf_path)
            ocr_texts = []
            for page in doc:
                pix = page.get_pixmap(dpi=300)
                img = Image.open(BytesIO(pix.tobytes("png")))
                text = pytesseract.image_to_string(img, lang=lang_code)
                ocr_texts.append(text)
            extracted_text = "\n".join(ocr_texts)

    st.success("âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    st.text_area("ğŸ“œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", extracted_text[:3000], height=400)

    # ì˜ì–´ ì˜¤íƒ€ ê²€ì‚¬
    spell_en = SpellChecker()
    english_words = re.findall(r"[A-Za-z]+", extracted_text)
    english_typos = spell_en.unknown(english_words)

    english_results = [
        {"ì–¸ì–´": "ì˜ë¬¸", "ë‹¨ì–´": word, "ì¶”ì²œ ìˆ˜ì •": spell_en.correction(word)}
        for word in english_typos
    ]

    # í•œê¸€ ì˜¤íƒ€ ê²€ì‚¬ (ê¸°ì´ˆ ê·œì¹™ ê¸°ë°˜)
    korean_typos = []
    for wrong, correct in korean_common_typos.items():
        if wrong in extracted_text:
            korean_typos.append({"ì–¸ì–´": "í•œê¸€", "ë‹¨ì–´": wrong, "ì¶”ì²œ ìˆ˜ì •": correct})

    # ê²°ê³¼ ì¶œë ¥
    all_typos = english_results + korean_typos
    if all_typos:
        st.error("âš ï¸ ì˜¤íƒ€ ë˜ëŠ” ì² ì ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.dataframe(all_typos, use_container_width=True)
    else:
        st.success("âœ… ì˜¤íƒ€ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    st.info("ğŸ‘† ë¨¼ì € AI ë˜ëŠ” PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
