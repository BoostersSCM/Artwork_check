import streamlit as st
import pdfplumber
import pytesseract
from PIL import Image
from io import BytesIO
import fitz  # PyMuPDF
import re
from spellchecker import SpellChecker
from hanspell import spell_checker

st.set_page_config(page_title="AI/PDF í…ìŠ¤íŠ¸ ì˜¤íƒ€ ê²€ì¦ê¸°", layout="wide")

st.title("ğŸ“„ AI/PDF ë‹¨ìƒì ì˜¤íƒ€ ê²€ì¦ê¸° (í•œê¸€+ì˜ë¬¸ í˜¼í•© ì§€ì›)")
st.markdown("""
ì´ ë„êµ¬ëŠ” **AI ë˜ëŠ” PDF ì›í™” íŒŒì¼**ì˜ í…ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ê³   
í•œê¸€ê³¼ ì˜ì–´ì˜ **ì² ì/ì˜¤íƒ€ë¥¼ ë™ì‹œì— ê²€ì¦**í•©ë‹ˆë‹¤.  
Poppler ì„¤ì¹˜ ì—†ì´ Streamlit Cloudì—ì„œë„ OCR ê¸°ëŠ¥ì´ ë™ì‘í•©ë‹ˆë‹¤.
---
""")

# OCR ì–¸ì–´ ì„¤ì •
lang_option = st.sidebar.selectbox(
    "OCR ì¸ì‹ ì–¸ì–´",
    ["í•œê¸€ë§Œ (kor)", "ì˜ì–´ë§Œ (eng)", "í•œê¸€+ì˜ì–´ (kor+eng)"],
    index=2
)
lang_code = lang_option.split("(")[-1].replace(")", "").strip()

uploaded_file = st.file_uploader("ğŸ“„ AI ë˜ëŠ” PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "ai"])

if uploaded_file:
    with st.spinner("ğŸ” í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            pdf_path = tmp_file.name

        extracted_text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                pages_text = [p.extract_text() for p in pdf.pages if p.extract_text()]
                extracted_text = "\n".join(pages_text)
        except Exception:
            extracted_text = ""

        # OCR fallback
        if len(extracted_text.strip()) < 50:
            st.info(f"ğŸ“¸ í…ìŠ¤íŠ¸ ì¸ì‹ ë¶ˆê°€ â†’ OCR ëª¨ë“œ ì „í™˜ ({lang_option})")
            doc = fitz.open(pdf_path)
            text_blocks = []
            for page in doc:
                pix = page.get_pixmap(dpi=300)
                img = Image.open(BytesIO(pix.tobytes("png")))
                ocr_text = pytesseract.image_to_string(img, lang=lang_code)
                text_blocks.append(ocr_text)
            extracted_text = "\n".join(text_blocks)

    st.success("âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ!")
    st.text_area("ğŸ“œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", extracted_text[:3000], height=400)

    # ------------------------
    # ì˜¤íƒ€ ê²€ì¦ ë¡œì§
    # ------------------------
    st.markdown("## âœï¸ ì˜¤íƒ€ ê²€ì¦ ê²°ê³¼")

    # 1ï¸âƒ£ ì˜ì–´ ì² ì ê²€ì‚¬
    spell_en = SpellChecker()
    english_words = re.findall(r"[A-Za-z]+", extracted_text)
    english_typos = spell_en.unknown(english_words)

    english_results = []
    for word in english_typos:
        suggestion = spell_en.correction(word)
        english_results.append({"ë‹¨ì–´": word, "ì œì•ˆ": suggestion})

    # 2ï¸âƒ£ í•œê¸€ ë§ì¶¤ë²• ê²€ì‚¬
    korean_sentences = re.findall(r"[ê°€-í£\s]+", extracted_text)
    korean_text = " ".join(korean_sentences)
    checked = spell_checker.check(korean_text)
    korean_typos = []
    if checked.errors > 0:
        for token, orig, cand, error in checked.words:
            if error:
                korean_typos.append({"ë‹¨ì–´": token, "ì œì•ˆ": cand})

    # ê²°ê³¼ ì¶œë ¥
    if english_results or korean_typos:
        st.error("âš ï¸ ì˜¤íƒ€ ë˜ëŠ” ì² ì ì˜¤ë¥˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        if english_results:
            st.subheader("ğŸ…°ï¸ ì˜ì–´ ì˜¤íƒ€")
            st.table(english_results)
        if korean_typos:
            st.subheader("ğŸ‡°ğŸ‡· í•œê¸€ ì˜¤íƒ€")
            st.table(korean_typos)
    else:
        st.success("âœ… ì˜¤íƒ€ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

else:
    st.info("ğŸ‘† ë¨¼ì € AI ë˜ëŠ” PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
